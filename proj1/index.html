<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Project Portfolio</title>
    <style>
        body {   
          font-family: Arial, sans-serif;
          margin: 0;
          padding: 0;
          background-color: black; /* Slightly grey background for the page */
        }
        
        header {
          background-color: #f2f2f0; /* Dark grey top banner */
          color: white;
          text-align: center;
          padding: 2rem 1rem; /* Spacing to make the banner large */
          color: white;
        }
        
        header h1 {
          margin: 0;
          font-size: 2rem;
        }
        
        header h2 {
          margin: 1rem 0 0 0;
          font-size: 1.5rem;
        }
        
        .big_container {
          max-width: 1000px;
          margin: 1rem auto; /* Centers the container */
          background-color: silver; /* White background for content */
          padding: 1rem;
          border-radius: 5px;
          box-shadow: 0 0 10px rgba(255, 255, 255, 0.4); /* Subtle shadow for depth */
          color: white;   
        }
            
        .container {
          max-width: 900px;
          margin: 2rem auto; /* Centers the container */
          background-color: #f2f2f0; /* White background for content */
          padding: 2rem;
          border-radius: 5px;
          box-shadow: 0 0 10px rgba(255, 255, 255, 0.4); /* Subtle shadow for depth */
          color: black;
        }
        
        .container a {
          color: #007bff; /* Blue link for "Back to Home" */
          text-decoration: none;
        }
        
        .container a:hover {
          text-decoration: underline;
        }
        
        .container h3 {
          font-size: 1.5rem;
          margin-top: 2rem;
        }
        
        .container p {
          line-height: 1.6; /* Improved readability for paragraphs */
        }
      </style>
</head>
    
<body>
    <header>
        <h1>CS 180 Project 1</h1>
            <h2>Images of the Russian Empire</h2>
    </header>
        <div class="container">
            <h2>Project Overview</h2>
            <p>Objective: Process Prokudin-Gorskiiâ€™s digitized glass plate images to reconstruct full-color photos.
                      Images were split into three grayscale channels (R, G, B), aligned using an x, y translation model, and stacked to form a single RGB image that best captures the original scene's true beauty!</p>
        </div>
    
        <div class="container">
            <h2>Algorithm Overview & Problems Encountered</h2>
                <p><strong>Preprocessing:</strong> After cropping out the B, G, and R images from the original triplet, my pipeline cropps 10% of the image borders to eliminate potential alignment noise caused by marginal artifacts, uneven exposure, or border effects. This pre-processing step ensures that the alignment focuses on the central and structurally significant portion of the image.</p>
                <p><strong>Low Resolution Images:</strong> For images with resolution below 1000 pixels in either dimension (.jpg images), my alignment algorithm follows a single-scale alignment strategy, which is optimized for accuracy at the cost of computational efficiency since it is a brute force approach.
                    The alignment is carried out using <code>_align_single_scale</code>, which performs an exhaustive search over a defined window (default is +-15 pixels) around a shift center (default is 0 shift), evaluating candidate displacements via an image similarity metric (more on this below).
                    For each potential (dx, dy) shift, the source channel is spatially rolled and compared against the reference using the computed similarity score. The shift that maximizes this score is selected as the optimal alignment. This approach is both accurate and reasonably fast for small or moderately-sized images. 
                    For higher-resolution images, however, this method falls apart as it takes too long.</p>
                <p><strong>High Resolution Images:</strong> For high-resolution images (i.e., those with either dimension greater than 1000 pixels), the alignment algorithm employs a multi-scale pyramid alignment strategy designed to handle the large search space efficiently while maintaining sub-pixel accuracy. 
                    This approach begins with recursive image downsampling, using a Gaussian pyramid scheme in the <code>_align_multiscale</code> function. The source and reference images are successively rescaled by a factor of 0.5 per level (with <code>anti_aliasing=True</code> to preserve structural integrity). 
                    At the coarsest scale (default set to 5 levels deep), the algorithm performs a coarse alignment via the <code>_align_single_scale</code> function, searching for the best (dx, dy) displacement using an image similiarity metric. 
                    After finding the best shift at the lowest resolution, the algorithm propagates this alignment up the pyramid, doubling the shift at each level to approximate the corresponding shift center in higher resolutions. At each level, the algorithm performs a local refinement step in a narrow window (default set to +-5 pixels) around the upscaled shift center.
                    This hierarchical refinement continues recursively until the full-resolution images are aligned. By combining global context from coarse levels with precision from fine levels, the multi-scale pipeline efficiently and accurately aligns the larger (.tif) images. This strategy significantly reduces computational cost compared to exhaustive full-resolution search!</p>
                <p><strong>Image Similarity Metric:</strong> After experimenting with both the Euclidean Distance (L2 Norm) metric and the Normalized Cross-Correlation (NCC) metric, I opted for the NCC metric because it proved to be more robust. Since NCC effectively "de-means" the data (normalized), it is resistant to pixel intensity shifts across images.
                    Additionally, the image <code>emir.tif</code> was especially problematic since it didn't have the same brightness values (i.e., "different color channels"). To resolve this I modified the NCC computation function by incorporating Sobel edge maps. 
                    By applying Sobel filters before NCC, the algorithm focuses more on structural edge features (i.e., high-contrast/rapid-change regions) and less on brightness and color intensity differences between pixel pairs. This addition finally enabled <code>emir.tif</code> to be recovered in all its beauty!</p>
        </div>
    
        <div class="container">
            <h2>Results</h2>
                <h3>Low Resolution Images</h3>
                    <p>cathedral.jpg<br>Green displacement: (dx=2, dy=5)<br>Red displacement: (dx=3, dy=12)</p>
                        <img src="media/cathedral_aligned.jpg" alt="cathedral aligned" width="300">
                    <p>monastery.jpg<br>Green displacement: (dx=2, dy=-3)<br>Red displacement: (dx=2, dy=3)</p>
                        <img src="media/monastery_aligned.jpg" alt="monastery aligned" width="300">
                <h3>High Resolution Images</h3>
                    <p>church.tif<br>Green displacement: (dx=4, dy=25)<br>Red displacement: (dx=-4, dy=58)</p>
                        <img src="media/church_aligned.jpg" alt="church aligned" width="300">
                        
                <h3>My Own Examples</h3>
                    <p>Detali_sobora_v_Milanie.tif<br>Green displacement: (dx=-18, dy=-10)<br>Red displacement: (dx=-52, dy=0)</p>
                        <img src="media/Detali_sobora_v_Milanie_aligned.jpg" alt="Detali_sobora_v_Milanie aligned" width="300">
            
        </div>
</body>
</html>
